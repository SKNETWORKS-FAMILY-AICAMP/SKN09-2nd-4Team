{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ\n",
    "y = df['churn']\n",
    "X = df.drop(columns=['churn'])\n",
    "\n",
    "# ÌïôÏäµ Î∞è ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# üéØ **ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏµúÏ†ÅÌôî (Optuna)**\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 3),  # Ïù¥ÌÉà Í≥†Í∞ù ÎπÑÏú® Ï¶ùÍ∞Ä\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'use_label_encoder': False,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Î™®Îç∏ ÌïôÏäµ\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ÏòàÏ∏° ÌôïÎ•†\n",
    "    y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # AUC ÌèâÍ∞Ä Í∏∞Ï§Ä\n",
    "    return roc_auc_score(y_test, y_probs)\n",
    "\n",
    "# **Optuna Ïã§Ìñâ**\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Ï†ÅÏö©\n",
    "best_params = study.best_params\n",
    "best_xgb_model = xgb.XGBClassifier(**best_params)\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# ÏòàÏ∏° ÌôïÎ•†\n",
    "y_probs = best_xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# AUC Score Í≥ÑÏÇ∞\n",
    "auc_score = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "# ÏµúÏ†Å Threshold Ï∞æÍ∏∞\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "y_pred_optimal = (y_probs > best_threshold).astype(int)\n",
    "\n",
    "# ÏµúÏ†Å Threshold Ï†ÅÏö© ÌõÑ ÌèâÍ∞Ä\n",
    "accuracy_optimal = accuracy_score(y_test, y_pred_optimal)\n",
    "report_optimal = classification_report(y_test, y_pred_optimal, digits=4)\n",
    "\n",
    "# Precision-Recall Curve ÏãúÍ∞ÅÌôî\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, precision[:-1], label=\"Precision\", linestyle=\"--\")\n",
    "plt.plot(thresholds, recall[:-1], label=\"Recall\")\n",
    "plt.axvline(x=best_threshold, color=\"red\", linestyle=\"dashed\", label=f\"Best Threshold ({best_threshold:.4f})\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision-Recall Tradeoff\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(f'Best Hyperparameters: {best_params}')\n",
    "print(f'Best Threshold: {best_threshold:.4f}')\n",
    "print(f'Adjusted Accuracy: {accuracy_optimal:.4f}')\n",
    "print(f'AUC Score: {auc_score:.4f}')\n",
    "print('Classification Report:\\n', report_optimal)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
